---
title: "Databases"
subtitle: "CFA Data Pipelines Workshop - Week 3"
format:
  revealjs:
    theme: simple
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: ../ForeSITE-logo.png
---

## Overview

Today's topics:

- SQL fundamentals review
- Connecting to databases
- Writing efficient queries
- Object-Relational Mapping (ORMs)
- Transactions and ACID properties

## Why Databases?

- **Structured storage**: Organized data
- **Query power**: Filter and aggregate
- **Concurrency**: Multiple users
- **ACID guarantees**: Data integrity: (Atomicity, Consistency, Isolation, and Durability)
- **Scalability**: Handle large datasets

## Database Types

:::: {.columns}

::: {.column width="33%"}
**Relational (SQL)**

- PostgreSQL
- MySQL
- SQLite
- SQL Server
:::

::: {.column width="33%"}
**Non-relational (NoSQL)**

- MongoDB
- Redis
- Cassandra
- DynamoDB
:::

::: {.column width="33%"}
**Specialized**

- Neo4j (Graph)
- Apache Spark (Big Data)
- Hadoop (Big Data)
- InfluxDB (Time-series)
:::

::::

Focus today: SQL databases

## Relational Databases

**What makes a database "relational"?**

- Data organized into **tables** (relations)
- Each table has **rows** (records) and **columns** (fields)
- Tables connected through **relationships**
- **Primary keys** uniquely identify rows
- **Foreign keys** link tables together
- Enforces **data integrity** and reduces redundancy

## Relational Database Example

Healthcare system with related tables:

```{mermaid}
%%| fig-width: 10
%%| fig-height: 4
erDiagram
    direction LR
    PATIENTS ||--o{ OUTPATIENT_VISITS : has
    OUTPATIENT_VISITS }o--|| PROVIDERS : seen_by
    OUTPATIENT_VISITS }o--|| DIAGNOSES : assigned
    
    PATIENTS {
        int patient_id PK "ðŸ”‘"
        string name
        date date_of_birth
        string insurance_id
    }
    
    OUTPATIENT_VISITS {
        int visit_id PK "ðŸ”‘"
        int patient_id FK "ðŸ”—"
        int provider_id FK "ðŸ”—"
        int diagnosis_id FK "ðŸ”—"
        date visit_date
    }
    
    PROVIDERS {
        int provider_id PK "ðŸ”‘"
        string name
        string specialty
    }
    
    DIAGNOSES {
        int diagnosis_id PK "ðŸ”‘"
        string icd_code
        string description
    }
```

## Workshop Database

**healthcare.db** - Sample SQLite database

Run `exercises/03-healthcare-database.py` to create:

- **10 patients** with demographics and insurance
- **7 providers** across 4 specialties
- **10 diagnoses** with ICD-10 codes
- **25 outpatient visits** over 6 months

All examples today use this database!

## SQL Fundamentals

**Structured Query Language (SQL)**

Basic operations:

- `SELECT`: Retrieve data
- `INSERT`: Add data
- `UPDATE`: Modify data
- `DELETE`: Remove data

## SELECT Statement

```sql
-- Basic select
SELECT patient_id, name FROM patients;

-- All columns
SELECT * FROM patients;

-- With conditions
SELECT name, date_of_birth 
FROM patients 
WHERE insurance_id IS NOT NULL;

-- With sorting
SELECT name, visit_date 
FROM outpatient_visits 
ORDER BY visit_date DESC;
```

## Filtering with WHERE

```sql
-- Comparison operators
SELECT * FROM outpatient_visits WHERE visit_date > '2024-01-01';

-- Multiple conditions
SELECT * FROM outpatient_visits 
WHERE visit_date >= '2024-01-01' 
  AND provider_id = 5;

-- Pattern matching
SELECT * FROM patients 
WHERE name LIKE 'Smith%';

-- IN clause
SELECT * FROM providers 
WHERE specialty IN ('Cardiology', 'Neurology');
```

## Aggregation

```sql
-- Count records
SELECT COUNT(*) FROM patients;

-- Count visits per patient
SELECT 
    patient_id,
    COUNT(*) as visit_count
FROM outpatient_visits
GROUP BY patient_id;

-- Group by provider specialty
SELECT 
    specialty,
    COUNT(*) as provider_count
FROM providers
GROUP BY specialty;
```

## Joins

```sql
-- Inner join
SELECT p.name, v.visit_date, pr.name as provider_name
FROM patients p
INNER JOIN outpatient_visits v ON p.patient_id = v.patient_id
INNER JOIN providers pr ON v.provider_id = pr.provider_id;

-- Left join
SELECT p.name, COUNT(v.visit_id) as visit_count
FROM patients p
LEFT JOIN outpatient_visits v ON p.patient_id = v.patient_id
GROUP BY p.name;
```

## Connecting to Databases

### Python with SQLite

```python
import sqlite3

# Connect to database
conn = sqlite3.connect('database.db')
cursor = conn.cursor()

# Execute query
cursor.execute('SELECT * FROM users')
rows = cursor.fetchall()

# Close connection
conn.close()
```

## Python with PostgreSQL

```python
import psycopg2

# Connect
conn = psycopg2.connect(
    host="localhost",
    database="mydb",
    user="user",
    password="password"
)

cursor = conn.cursor()
cursor.execute("SELECT * FROM users")
rows = cursor.fetchall()

conn.close()
```

## R with DBI

```r
library(DBI)

# SQLite
con <- dbConnect(RSQLite::SQLite(), "database.db")

# Query
result <- dbGetQuery(con, "SELECT * FROM users")

# Close
dbDisconnect(con)
```

## Parameterized Queries

**Always use parameterized queries!**

```python
# WRONG - SQL injection risk
user_id = input("Enter user ID: ")
cursor.execute(f"SELECT * FROM users WHERE id = {user_id}")

# CORRECT - Safe from SQL injection
user_id = input("Enter user ID: ")
cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
```

## Object-Relational Mapping (ORM)

ORMs map database tables to objects:

- Write less SQL
- Database-agnostic code
- Type safety
- May sacrifice performance

## SQLAlchemy (Python)

```python
from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()

class User(Base):
    __tablename__ = 'users'
    id = Column(Integer, primary_key=True)
    name = Column(String)
    email = Column(String)

# Create engine and session
engine = create_engine('sqlite:///database.db')
Session = sessionmaker(bind=engine)
session = Session()

# Query
users = session.query(User).filter(User.email.like('%@example.com')).all()
```

## dbplyr (R)

```r
library(dplyr)
library(dbplyr)

# Connect
con <- DBI::dbConnect(RSQLite::SQLite(), "database.db")

# Reference table
users <- tbl(con, "users")

# Query with dplyr syntax
active_users <- users %>%
  filter(status == "active") %>%
  select(name, email) %>%
  collect()  # Execute query
```

## Transactions

A transaction is a sequence of operations performed as a single logical unit of work.

```python
conn = sqlite3.connect('database.db')
cursor = conn.cursor()

try:
    cursor.execute("BEGIN TRANSACTION")
    cursor.execute("UPDATE accounts SET balance = balance - 100 WHERE id = 1")
    cursor.execute("UPDATE accounts SET balance = balance + 100 WHERE id = 2")
    conn.commit()
except Exception as e:
    conn.rollback()
    print(f"Transaction failed: {e}")
finally:
    conn.close()
```

## ACID Properties

- **Atomicity**: All or nothing
- **Consistency**: Valid state transitions
- **Isolation**: Concurrent transactions don't interfere
- **Durability**: Committed data persists

## Query Optimization

### Use Indexes

```sql
-- Create index
CREATE INDEX idx_users_email ON users(email);

-- Query benefits from index
SELECT * FROM users WHERE email = 'user@example.com';
```

### Avoid SELECT *

```sql
-- Less efficient
SELECT * FROM users;

-- More efficient - only needed columns
SELECT id, name, email FROM users;
```

## Explain Query Plans

```sql
-- See how database executes query
EXPLAIN QUERY PLAN
SELECT u.name, COUNT(o.id)
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.name;
```

Helps identify:

- Missing indexes
- Inefficient joins
- Full table scans

## Connection Pooling

Reuse database connections:

```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    'postgresql://user:pass@localhost/db',
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20
)
```

Benefits:

- Faster connections
- Limited concurrent connections
- Better resource management

## Best Practices

1. **Use parameterized queries**: Prevent SQL injection
2. **Index appropriately**: Balance read/write performance
3. **Use transactions**: Ensure data consistency
4. **Close connections**: Avoid resource leaks
5. **Handle errors**: Catch and log database errors
6. **Limit result sets**: Use LIMIT/pagination
7. **Monitor performance**: Log slow queries

## Common Pitfalls

- SQL injection vulnerabilities
- Not closing connections
- N+1 query problem (ORMs)
- Missing indexes on large tables
- Not using transactions for multi-step operations
- Fetching too much data at once

## Hands-on Exercise

Build a script that:

1. Connects to a database
2. Creates a table
3. Inserts sample data
4. Queries and filters data
5. Uses transactions
6. Handles errors properly

## Real-world Example

```python
import sqlite3
import pandas as pd

# Connect and load data
conn = sqlite3.connect('sales.db')

# Query to pandas DataFrame
query = """
    SELECT 
        DATE(order_date) as date,
        SUM(total) as daily_sales
    FROM orders
    WHERE order_date >= date('now', '-30 days')
    GROUP BY DATE(order_date)
    ORDER BY date
"""

df = pd.read_sql_query(query, conn)
print(df)

conn.close()
```

## Questions?

Next session: Data Cleaning

## Resources

- [SQL Tutorial](https://www.w3schools.com/sql/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [PostgreSQL Tutorial](https://www.postgresqltutorial.com/)
- [dbplyr Documentation](https://dbplyr.tidyverse.org/)
